# getv â€” Universal .env Variable Manager

[![PyPI version](https://badge.fury.io/py/getv.svg)](https://badge.fury.io/py/getv)
[![Python versions](https://img.shields.io/pypi/pyversions/getv)](https://pypi.org/project/getv/)
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Downloads](https://img.shields.io/pypi/dm/getv)](https://pypi.org/project/getv/)
[![Tests](https://github.com/wronai/getv/workflows/Tests/badge.svg)](https://github.com/wronai/getv/actions)

Read, write, encrypt, and delegate environment variables across services and devices.

![img.png](img.png)

Copy to the clipboard and run `getv grab` to detect and save the API key 

```bash
$ getv grab

Detected:  groq (GROQ_API_KEY)
Key:       gsk_Y1xV...TNpA
Source:    Prefix match
Domain:    console.groq.com
Category:  llm
Profile:   ~/.getv/llm/groq.env

Saved to /home/tom/.getv/llm/groq.env

Usage:
  getv get llm groq GROQ_API_KEY
  getv exec llm groq -- python app.py
```

without any plugins, managers, or integrations...


## ðŸ“‘ Table of Contents

- [Why getv?](#why-getv)
- [Install](#install)
- [Quick Start](#quick-start)
- [Profile Directory Structure](#profile-directory-structure)
- [App Defaults](#app-defaults)
- [Integrations](#integrations)
- [Grab â€” Clipboard API Key Detection](#grab--clipboard-api-key-detection)
- [One-liner Examples](#one-liner-examples)
- [Security](#security)
- [Format Export](#format-export)
- [CLI Reference](#cli-reference)
- [Examples](#examples)
- [Environment Variables](#environment-variables)
- [Adopted by](#adopted-by)
- [License](#license)

## Why getv?

Every project reinvents `.env` parsing. `getv` provides one library for:

- **Reading/writing** `.env` files with comment preservation
- **Profile management** â€” named configs for devices, LLM providers, databases
- **App defaults** â€” per-app profile selection (`~/.getv/defaults/APP.conf`)
- **Integrations** â€” plugins for SSH, LiteLLM, Ollama, Docker, curl, Pydantic
- **Secret masking** â€” automatic detection and masking of passwords/keys in logs
- **Encryption** â€” Fernet-based encryption of sensitive values for safe transport
- **Format export** â€” dict, JSON, shell, docker-compose, pydantic BaseSettings
- **CLI** â€” manage profiles from the command line

## Install

```bash
pip install getv                   # core
pip install "getv[crypto]"         # + encryption (Fernet)
pip install "getv[pydantic]"       # + pydantic BaseSettings export
pip install "getv[all]"            # everything
```

**v0.2.1** â€” New: `getv grab` (clipboard API key auto-detection), integrations, app defaults, 9 examples

## Quick Start

### Python API

```python
from getv import EnvStore, ProfileManager

# Single .env file
store = EnvStore("~/.myapp/.env")
store.set("DB_HOST", "localhost").set("DB_PORT", "5432").save()
print(store.get("DB_HOST"))  # "localhost"

# Profile manager â€” multiple named configs
pm = ProfileManager("~/.getv")
pm.add_category("devices", required_keys=["RPI_HOST", "RPI_USER"])
pm.add_category("llm", required_keys=["LLM_MODEL"])

pm.set("devices", "rpi3", {
    "RPI_HOST": "192.168.1.10",
    "RPI_USER": "pi",
    "RPI_PASSWORD": "secret",
    "RPI_PORT": "22",
})

pm.set("llm", "groq", {
    "LLM_MODEL": "groq/llama-3.3-70b-versatile",
    "GROQ_API_KEY": "gsk_xxx",
})

# Merge profiles on top of base config
base = {"APP_NAME": "myapp", "RPI_HOST": "default"}
cfg = pm.merge_profiles(base, devices="rpi3", llm="groq")
# cfg["RPI_HOST"] == "192.168.1.10" (overridden by device profile)
# cfg["LLM_MODEL"] == "groq/llama-3.3-70b-versatile"

# App-specific defaults
from getv.app_defaults import AppDefaults
defaults = AppDefaults("myapp")
defaults.set("llm", "groq").set("devices", "rpi3")
# Later: cfg = pm.merge_profiles(base, **defaults.as_profile_kwargs())
```

### CLI

```bash
# Set variables
getv set devices rpi3 RPI_HOST=192.168.1.10 RPI_USER=pi RPI_PASSWORD=secret

# Get a single variable
getv get devices rpi3 RPI_HOST
# â†’ 192.168.1.10

# List all categories
getv list
#   devices/ (2 profiles)
#   llm/ (3 profiles)

# List profiles in a category (secrets masked)
getv list devices
#   rpi3: RPI_HOST=192.168.1.10, RPI_USER=pi, RPI_PASSWORD=secr***

# Show all variables (unmasked)
getv list devices rpi3 --show-secrets

# Export to different formats
getv export devices rpi3 --format json
getv export devices rpi3 --format shell
getv export devices rpi3 --format pydantic
getv export llm groq --format docker

# Encrypt sensitive values (Fernet)
getv encrypt devices rpi3
# â†’ Generated key: ~/.getv/.fernet.key
# â†’ Encrypted sensitive values in devices/rpi3

# Decrypt
getv decrypt devices rpi3

# Delete a profile
getv delete devices old-rpi

# Execute commands with profile environment
getv exec llm groq -- python my_script.py
getv exec devices rpi3 -- ssh pi@host uname -a

# SSH to devices using profile
getv ssh rpi3                    # interactive shell
getv ssh rpi3 "uname -a"        # run remote command

# Make authenticated API calls
getv curl groq https://api.groq.com/openai/v1/models
getv curl openai https://api.openai.com/v1/models -X POST -d '{"model":"gpt-4"}'

# Set app-specific defaults
getv use myapp llm groq
getv use myapp devices rpi3

# Show app defaults
getv defaults              # list all apps
getv defaults myapp       # show myapp defaults
```

## Profile Directory Structure

```text
~/.getv/                       â† GETV_HOME (configurable)
â”œâ”€â”€ .fernet.key                â† encryption key (chmod 600)
â”œâ”€â”€ defaults/                  â† per-app default profile selections
â”‚   â”œâ”€â”€ fixpi.conf             â†’ llm=groq, devices=rpi3
â”‚   â”œâ”€â”€ prellm.conf            â†’ llm=openrouter
â”‚   â””â”€â”€ marksync.conf          â†’ llm=ollama-local
â”œâ”€â”€ devices/
â”‚   â”œâ”€â”€ rpi3.env
â”‚   â”œâ”€â”€ rpi4-prod.env
â”‚   â””â”€â”€ nvidia.env
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ groq.env
â”‚   â”œâ”€â”€ openrouter.env
â”‚   â””â”€â”€ ollama-local.env
â””â”€â”€ ollama/
    â”œâ”€â”€ local.env
    â””â”€â”€ gpu-server.env
```

Each `.env` file is a standard `KEY=VALUE` file:

```bash
# ~/.getv/devices/rpi3.env
RPI_HOST=192.168.1.10
RPI_USER=pi
RPI_PASSWORD=secret
RPI_PORT=22
```

## App Defaults

Each app remembers which profile to use â€” so `fixpi` uses Groq while `marksync` uses Ollama:

```bash
# Set defaults (one-time)
getv use fixpi llm groq
getv use fixpi devices rpi3
getv use prellm llm openrouter
getv use marksync llm ollama-local

# Check what's configured
getv defaults
#   fixpi: devices=rpi3, llm=groq
#   marksync: llm=ollama-local
#   prellm: llm=openrouter

# In your app startup code:
from getv import AppDefaults, ProfileManager
defaults = AppDefaults("fixpi")
pm = ProfileManager("~/.getv")
cfg = pm.merge_profiles({}, **defaults.as_profile_kwargs())
```

## Integrations

getv ships with plugins for common tools:

### SSH

```bash
# Setup once
getv set devices rpi3 RPI_HOST=192.168.1.10 RPI_USER=pi RPI_PASSWORD=raspberry

# Connect
getv ssh rpi3                       # interactive shell
getv ssh rpi3 "uname -a"            # remote command
```

```python
from getv.integrations.ssh import SSHEnv
ssh = SSHEnv.from_profile("rpi3")
ssh.run("uname -a", capture=True)            # subprocess
params = ssh.as_paramiko_kwargs()            # for paramiko
```

### LiteLLM

```bash
# Setup providers
getv set llm groq LLM_MODEL=groq/llama-3.3-70b-versatile GROQ_API_KEY=gsk_xxx
getv set llm openrouter LLM_MODEL=openrouter/google/gemini-2.0-flash-exp:free OPENROUTER_API_KEY=sk-or-xxx

# Switch at runtime
getv exec llm groq -- python my_script.py
getv exec llm openrouter -- python my_script.py
```

```python
from getv.integrations.litellm import LiteLLMEnv
llm = LiteLLMEnv.from_profile("groq")
llm.activate()  # sets os.environ
# or: litellm.completion(**llm.as_completion_kwargs(), messages=[...])
```

### Ollama

```bash
getv set ollama gpu-server OLLAMA_API_BASE=http://192.168.1.50:11434 OLLAMA_MODEL=qwen2.5-coder:14b
getv exec ollama gpu-server -- ollama run qwen2.5-coder:14b
```

```python
from getv.integrations.ollama import OllamaEnv
oll = OllamaEnv.from_profile("gpu-server")
oll.activate()  # sets OLLAMA_API_BASE in env
print(oll.litellm_model())  # "ollama/qwen2.5-coder:14b"
```

### Docker

```bash
getv export llm groq --format docker > /tmp/groq.env
docker run --env-file /tmp/groq.env my-llm-app:latest
```

```python
from getv.integrations.docker import DockerEnv
denv = DockerEnv.from_profiles(llm="groq", devices="rpi3")
denv.write_env_file("/tmp/docker.env")
print(denv.compose_environment())  # docker-compose block
```

### curl

```bash
# API call with auth from profile
getv curl groq https://api.groq.com/openai/v1/models
getv curl openai https://api.openai.com/v1/models
```

### Pydantic Settings

```python
from getv.integrations.pydantic_env import load_profile_into_env
load_profile_into_env("llm", "groq")  # inject into os.environ
settings = MySettings()               # pydantic reads from env
```

### Subprocess / Pipe

```bash
# Run any command with profile env injected
getv exec llm groq -- python my_script.py
getv exec devices rpi3 -- ansible-playbook deploy.yml

# Shell eval
eval $(getv export llm groq --format shell)
```

## Grab â€” Clipboard API Key Detection

Copy an API key â†’ run `getv grab` â†’ auto-detected, saved.

```bash
# 1. Copy API key from console.groq.com (Ctrl+C)
# 2. Run:
getv grab

# Output:
# Detected:  groq (GROQ_API_KEY)
# Key:       gsk_abc1...9jkl
# Source:    Prefix match
# Domain:    console.groq.com
# Category:  llm
# Profile:   ~/.getv/llm/groq.env
# Saved to /home/user/.getv/llm/groq.env

# Options:
getv grab --dry-run           # detect only, don't save
getv grab --category api      # override category
getv grab --provider myname   # override provider name
getv grab --no-browser        # skip browser history check
```

### Supported prefixes (auto-detected)

| Prefix | Provider | Env Var | Category |
|--------|----------|---------|----------|
| `sk-ant-` | Anthropic | `ANTHROPIC_API_KEY` | llm |
| `sk-or-` | OpenRouter | `OPENROUTER_API_KEY` | llm |
| `sk-` / `sk-proj-` | OpenAI | `OPENAI_API_KEY` | llm |
| `gsk_` | Groq | `GROQ_API_KEY` | llm |
| `key-` | Mistral | `MISTRAL_API_KEY` | llm |
| `xai-` | xAI | `XAI_API_KEY` | llm |
| `pplx-` | Perplexity | `PERPLEXITY_API_KEY` | llm |
| `nvapi-` | NVIDIA | `NVIDIA_API_KEY` | llm |
| `hf_` | HuggingFace | `HF_API_KEY` | llm |
| `r8_` | Replicate | `REPLICATE_API_TOKEN` | llm |
| `ghp_` | GitHub | `GITHUB_TOKEN` | tokens |
| `glpat-` | GitLab | `GITLAB_TOKEN` | tokens |
| `AKIA` | AWS | `AWS_ACCESS_KEY_ID` | cloud |
| `dop_v1_` | DigitalOcean | `DIGITALOCEAN_TOKEN` | cloud |
| `tskey-` | Tailscale | `TAILSCALE_API_KEY` | tokens |
| `SG.` | SendGrid | `SENDGRID_API_KEY` | email |
| `sk_live_` / `sk_test_` | Stripe | `STRIPE_API_KEY` | payments |

### Detection priority

1. **Key prefix** â€” covers ~90% of cases (instant)
2. **Browser history** â€” Chrome/Firefox SQLite (last 10 min)
3. **User prompt** â€” fallback

```python
# Python API
from getv.integrations.clipboard import ClipboardGrab

grab = ClipboardGrab()
result = grab.detect()  # reads clipboard, returns GrabResult or None

if result:
    print(result.provider, result.env_var)
    result.save()  # writes to ~/.getv/llm/groq.env
```

## One-liner Examples

### Popular API Tokens

```bash
# OpenAI
export OPENAI_API_KEY=$(getv get llm openai OPENAI_API_KEY) && python my_script.py

# GitHub
git clone https://$(getv get git github GH_TOKEN)@github.com/user/repo.git

# AWS
export AWS_ACCESS_KEY_ID=$(getv get aws prod AWS_ACCESS_KEY_ID) && \
export AWS_SECRET_ACCESS_KEY=$(getv get aws prod AWS_SECRET_ACCESS_KEY) && \
aws s3 ls

# Docker Hub
echo $(getv get docker hub DOCKERHUB_TOKEN) | docker login --username user --password-stdin

# Slack
curl -X POST -H 'Authorization: Bearer '$(getv get chat slack SLACK_BOT_TOKEN) \
  -H 'Content-type: application/json' --data '{"text":"Hello"}' \
  https://slack.com/api/chat.postMessage

# Multiple env vars
eval "$(getv export llm openai --format shell)" && python my_script.py

# Docker compose
getv export app production --format env > .env && docker-compose up

# Direct API calls
getv curl openai https://api.openai.com/v1/models
getv curl groq https://api.groq.com/openai/v1/chat/completions -X POST -d '{"model":"llama3-70b"}'
```

### Real-world One-liners with Pipes & Hacks

#### 1. Source profile directly into shell

```bash
source <(getv exec llm groq -- env | grep -E '^(GROQ_API_KEY|LLM_MODEL)=')
```

**Problem:** Chcesz szybko zaÅ‚adowaÄ‡ zmienne Å›rodowiskowe do bieÅ¼Ä…cej powÅ‚oki bez uruchamiania polecenia w `getv exec`.

**RozwiÄ…zanie:** Process substitution `<(...)` pozwala traktowaÄ‡ wyjÅ›cie polecenia jako plik. Filtrujemy tylko interesujÄ…ce nas zmienne.

**Wynik:** Zmienne `GROQ_API_KEY` i `LLM_MODEL` sÄ… dostÄ™pne w powÅ‚oce.

---

#### 2. UÅ¼ycie z curl (wywoÅ‚anie API)

```bash
getv exec llm groq -- curl -s https://api.groq.com/v1/models
```

**Problem:** Musisz wywoÅ‚aÄ‡ API LLM z autentykacjÄ…, ale nie chcesz hardkodowaÄ‡ klucza w skrypcie.

**RozwiÄ…zanie:** `getv exec` automatycznie wstrzykuje zmienne Å›rodowiskowe z profilu przed uruchomieniem polecenia.

**Wynik:** Curl wysyÅ‚a Å¼Ä…danie z nagÅ‚Ã³wkiem `Authorization: Bearer gsk_xxx`.

---

#### 3. UÅ¼ycie z Pythonem

```bash
getv exec llm groq -- python -c "import os; print(os.environ['GROQ_API_KEY'][:10])"
```

**Problem:** Pythonowy skrypt potrzebuje klucza API, ale nie chcesz przekazywaÄ‡ go jako argument.
**RozwiÄ…zanie:** Wstrzyknij profil do Å›rodowiska, Python czyta z `os.environ`.
**Wynik:** Skrypt widzi klucz bezpiecznie przechowywany w getv.

---

#### 4. UÅ¼ycie z Docker (jako env file)

```bash
docker run --env-file <(getv export llm groq) python:3 python -c "import os; print('OK')"
```

**Problem:** Docker wymaga pliku `.env` ale nie chcesz tworzyÄ‡ go rÄ™cznie.
**RozwiÄ…zanie:** Process substitution tworzy tymczasowy plik env na podstawie profilu getv.
**Wynik:** Kontener otrzymuje zmienne z profilu bez pliku na dysku.

---

#### 5. Export do .env

```bash
getv export llm groq > ~/.env.local && source ~/.env.local
```

**Problem:** Masz istniejÄ…cy projekt ktÃ³ry wymaga `.env` i chcesz uÅ¼yÄ‡ profilu getv.
**RozwiÄ…zanie:** Export do standardowego formatu .env, nastÄ™pnie ÅºrÃ³dÅ‚ujemy do powÅ‚oki.
**Wynik:** Wszystkie zmienne z profilu sÄ… dostÄ™pne w powÅ‚oce.

---

#### 6. UÅ¼ycie z jq (przetwarzanie JSON)

```bash
getv exec llm groq -- curl -s https://api.groq.com/v1/models | jq '.data[0].id'
```

**Problem:** API zwraca JSON, chcesz wyciÄ…gnÄ…Ä‡ konkretne pole.
**RozwiÄ…zanie:** Pipe JSON do jq do filtrowania.
**Wynik:** WyÅ›wietla pierwszy dostÄ™pny model ID.

---

#### 7. UÅ¼ycie z npx (np. Claude CLI)

```bash
getv exec llm groq -- npx -y @anthropic/claude-cli chat "hello"
```

**Problem:** NarzÄ™dzia npm potrzebujÄ… klucza API w Å›rodowisku.
**RozwiÄ…zanie:** Wstrzyknij profil, npx uruchamia narzÄ™dzie z dostÄ™pnym kluczem.
**Wynik:** Claude CLI ma dostÄ™p do API bez rÄ™cznej konfiguracji.

---

#### 8. UÅ¼ycie z litellm

```bash
getv exec llm groq -- litellm --model groq/llama-3.3-70b-versatile --temp 0 "hi"
```

**Problem:** LiteLLM to uniwersalny klient LLM, potrzebuje klucza i modelu.
**RozwiÄ…zanie:** Profil dostarcza obie zmienne, litellm wykrywa providera po prefiksie klucza.
**Wynik:** WywoÅ‚anie LLM przez litellm z profilem groq.

---

#### 9. UÅ¼ycie z ollama (lokalny model)

```bash
getv exec llm ollama -- ollama run llama3 "hello"
```

**Problem:** Ollama na zdalnym serwerze wymaga konfiguracji adresu i modelu.
**RozwiÄ…zanie:** Profil zawiera `OLLAMA_API_BASE` i `OLLAMA_MODEL`, exec je wstrzykuje.
**Wynik:** Ollama Å‚Ä…czy siÄ™ ze zdalnym serwerem zamiast localhost.

---

#### 10. SSH do urzÄ…dzenia z automatycznymi zmiennymi

```bash
getv ssh devices rpi3 "uptime"
```

**Problem:** SSH do urzÄ…dzenia IoT, musisz pamiÄ™taÄ‡ adres, uÅ¼ytkownika, port.
**RozwiÄ…zanie:** Profil getv przechowuje wszystko, `getv ssh` automatycznie Å‚Ä…czy.
**Wynik:** Zdalne polecenie wykonane bez rÄ™cznego wpisywania parametrÃ³w.

---

#### 11. Rsync z uÅ¼yciem profilu

```bash
getv exec devices rpi3 -- rsync -av /src/ rpi:/dest/
```

**Problem:** Rsync wymaga hosta, uÅ¼ytkownika - chcesz uÅ¼yÄ‡ profilu.
**RozwiÄ…zanie:** Profil definiuje RPI_HOST i RPI_USER, rsync uÅ¼ywa ich przez zmienne lub alias.
**Wynik:** Synchronizacja plikÃ³w ze zdalnym urzÄ…dzeniem.

---

#### 12. Import z istniejÄ…cego .env

```bash
getv import llm newprovider < .env
```

**Problem:** Masz istniejÄ…cy plik .env i chcesz zaimportowaÄ‡ do getv.
**RozwiÄ…zanie:** `getv import` parsuje .env i zapisuje do profilu.
**Wynik:** Nowy profil `llm/newprovider` z wszystkimi zmiennymi.

---

#### 13. Watch - monitorowanie zmian

```bash
watch -n 5 'getv get llm groq GROQ_API_KEY'
```

**Problem:** Chcesz sprawdziÄ‡ czy klucz siÄ™ nie zmieniÅ‚ (np. po rotacji).
**RozwiÄ…zanie:** Watch periodycznie odpytuje getv.
**Wynik:** Co 5 sekund wyÅ›wietla aktualnÄ… wartoÅ›Ä‡ klucza.

---

#### 14. Pipe do schowka (macOS)

```bash
getv get llm groq GROQ_API_KEY | pbcopy
```

**Problem:** Chcesz skopiowaÄ‡ klucz do schowka rÄ™cznie.
**RozwiÄ…zanie:** Pipe wyjÅ›cia do `pbcopy` (macOS).
**Wynik:** Klucz w schowku gotowy do wklejenia.

---

#### 15. ÅÄ…czenie profili (np. LLM + cloud razem)

```bash
cat <(getv export llm groq) <(getv export cloud aws) > combined.env
```

**Problem:** Potrzebujesz zmienne z wielu profili w jednym pliku.
**RozwiÄ…zanie:** Process substitution Å‚Ä…czy wyjÅ›cie dwÃ³ch profilÃ³w.
**Wynik:** Plik combined.env ze zmiennymi z obu profili.

---

#### 16. Szybkie sprawdzenie wszystkich kluczy LLM

```bash
getv list llm --show-secrets | grep -E '^[A-Z_]+='
```

**Problem:** Chcesz zobaczyÄ‡ wszystkie zmienne w kategori LLM.
**RozwiÄ…zanie:** List z maskowaniem, filtruj grepem.
**Wynik:** Czysta lista KEY=VALUE bezæ ¼å¼åŒ–owania.

---

#### 17. UÅ¼ycie z httpie (alternatywa dla curl)

```bash
getv exec llm openai -- https GET https://api.openai.com/v1/models
```

**Problem:** Wolisz httpie od curl dla lepszego formatowania.
**RozwiÄ…zanie:** httpie automatycznie czyta zmienne Å›rodowiskowe.
**Wynik:** Åadnie sformatowane API response.

---

#### 18. Test poÅ‚Ä…czenia z providerem

```bash
getv exec llm groq -- curl -s -w "\nHTTP: %{http_code}\n" https://api.groq.com/v1/models
```

**Problem:** Chcesz szybko sprawdziÄ‡ czy klucz dziaÅ‚a.
**RozwiÄ…zanie:** curl z flagÄ… `-w` pokazuje kod HTTP.
**Wynik:** Widzisz czy autentykacja przeszÅ‚a (200) czy nie (401).

---

#### 19. Export dla crona

```bash
(crontab -l 2>/dev/null; echo "0 * * * * . <(getv export llm groq --format shell) && /usr/bin/python /app/sync.py") | crontab -
```

**Problem:** Cron potrzebuje zmiennych Å›rodowiskowych.
**RozwiÄ…zanie:** Dodaj do crontab polecenie Å‚adujÄ…ce profil przed uruchomieniem.
**Wynik:** Cron job z dostÄ™pem do klucza API.

---

#### 20. Debug - pokaz wszystkie zmienne profilu

```bash
getv export llm groq --format shell | bash -x
```

**Problem:** Chcesz zobaczyÄ‡ co dokÅ‚adnie exportuje profil.
**RozwiÄ…zanie:** Uruchom export jako skrypt z debug mode.
**Wynik:** Widzisz kaÅ¼de polecenie export i jego efekt.

## Security

### Automatic Secret Detection

Keys matching these patterns are automatically masked in display/logs:

`PASSWORD`, `PASSWD`, `SECRET`, `TOKEN`, `API_KEY`, `APIKEY`,
`PRIVATE_KEY`, `ACCESS_KEY`, `ACCESS_TOKEN`, `AUTH`, `CREDENTIAL`

```python
from getv.security import mask_dict, is_sensitive_key

data = {"RPI_HOST": "10.0.0.1", "RPI_PASSWORD": "secret123"}
print(mask_dict(data))
# {"RPI_HOST": "10.0.0.1", "RPI_PASSWORD": "secr***"}
```

### Encryption for Transport

```python
from getv.security import generate_key, encrypt_store, decrypt_store

key = generate_key()
data = {"RPI_HOST": "10.0.0.1", "RPI_PASSWORD": "secret"}
encrypted = encrypt_store(data, key, only_sensitive=True)
# {"RPI_HOST": "10.0.0.1", "RPI_PASSWORD": "ENC:gAAA..."}

original = decrypt_store(encrypted, key)
# {"RPI_HOST": "10.0.0.1", "RPI_PASSWORD": "secret"}
```

## Format Export

| Format | Function | Output |
|--------|----------|--------|
| dict | `store.as_dict()` | `{"KEY": "val"}` |
| JSON | `to_json(data)` | `{"KEY": "val"}` |
| Shell | `to_shell_export(data)` | `export KEY='val'` |
| Docker | `to_docker_env(data)` | `KEY=val` |
| .env | `to_env_file(data)` | `KEY=val` |
| Pydantic | `to_pydantic_settings(data)` | Python class source |
| Pydantic model | `to_pydantic_model(data)` | BaseSettings instance |

## CLI Reference

| Command | Description |
|---------|-------------|
| `getv set CATEGORY PROFILE KEY=VAL...` | Create/update a profile |
| `getv get CATEGORY PROFILE KEY` | Get a single value |
| `getv list [CATEGORY [PROFILE]]` | List categories, profiles, or vars |
| `getv delete CATEGORY PROFILE` | Delete a profile |
| `getv export CATEGORY PROFILE --format FMT` | Export (json/shell/docker/env/pydantic) |
| `getv encrypt CATEGORY PROFILE` | Encrypt sensitive values |
| `getv decrypt CATEGORY PROFILE` | Decrypt values |
| `getv exec CATEGORY PROFILE -- CMD...` | Run command with profile env |
| `getv use APP CATEGORY PROFILE` | Set app default profile |
| `getv defaults [APP]` | Show app defaults |
| `getv ssh PROFILE [CMD]` | SSH to device from profile |
| `getv curl PROFILE URL` | Authenticated API call |
| `getv grab [--dry-run]` | Auto-detect API key from clipboard and save |

## Examples

See `examples/` directory:

| File | Description |
|------|-------------|
| `01_quick_start.py` | Centralized .env management |
| `02_ssh_from_profile.py` | SSH/SCP with paramiko/fabric |
| `03_litellm_multi_provider.py` | Switch LLM providers |
| `04_ollama_config.py` | Ollama local/remote/Docker |
| `05_docker_env.py` | Docker env files & compose |
| `06_app_defaults.py` | Per-app default profiles |
| `07_pipe_and_shell.sh` | Shell integration & pipes |
| `08_pydantic_settings.py` | Pydantic Settings bridge |
| `09_grab_api_key.py` | Clipboard API key auto-detection |

## Environment Variables

| Variable | Default | Description |
|---------|---------|-------------|
| `GETV_HOME` | `~/.getv` | Base directory for profiles |

## Adopted by

Projects using getv for `.env` management:

- **[fixpi](https://github.com/zlecenia/c2004/tree/main/fixPI)** â€” SSH + LLM diagnostic agent
- **[prellm](https://github.com/wronai/prellm)** â€” LLM preprocessing proxy
- **[code2logic](https://github.com/wronai/code2logic)** â€” Code analysis engine
- **[amen](https://github.com/wronai/amen)** â€” Intent-iterative AI gateway
- **[marksync](https://github.com/wronai/marksync)** â€” Markdown sync server
- **[curllm](https://github.com/wronai/curllm)** â€” LLM-powered web automation

## Development

```bash
git clone https://github.com/wronai/getv.git
cd getv
python -m venv .venv && source .venv/bin/activate
pip install -e ".[dev]"
pytest  # 128 tests
```

## License

Apache License 2.0 - see [LICENSE](LICENSE) for details.

## Author

Created by **Tom Sapletta** - [tom@sapletta.com](mailto:tom@sapletta.com)
